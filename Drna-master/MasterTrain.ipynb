{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MasterTrain.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMrCvKAeR3hx+5EK+5XwAyc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ebd479848fe14a9e9af0cb8df43614d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0b7f901113c143d18165eae5d46dcf05","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e1ccd86ac86f430faad278005926f0b8","IPY_MODEL_b61984e56eb54db8a2c46012a5b2ff20","IPY_MODEL_90c7727d6ccf4fa18b3a0dd52f4ad1d1"]}},"0b7f901113c143d18165eae5d46dcf05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e1ccd86ac86f430faad278005926f0b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5a3de439b99c42bfb9029a0d38e6d5a5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5801e1ac73994bf7a65a87ec775deefb"}},"b61984e56eb54db8a2c46012a5b2ff20":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f74764d2da724f5eac1d320330510a59","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":102530333,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":102530333,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0bf20de2450844f3bd44fadacf236383"}},"90c7727d6ccf4fa18b3a0dd52f4ad1d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_01f48500412a40b28770e68943343604","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 97.8M/97.8M [00:01&lt;00:00, 93.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4b9c990f1130401db179efb20c709ef5"}},"5a3de439b99c42bfb9029a0d38e6d5a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5801e1ac73994bf7a65a87ec775deefb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f74764d2da724f5eac1d320330510a59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0bf20de2450844f3bd44fadacf236383":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"01f48500412a40b28770e68943343604":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4b9c990f1130401db179efb20c709ef5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"mDOdbok4zVE4"},"source":["# Colab Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GaPpoYZSzX_o","executionInfo":{"status":"ok","timestamp":1638754812851,"user_tz":-540,"elapsed":30241,"user":{"displayName":"Mads Jungersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15054749878452554668"}},"outputId":"bcc6d854-563c-40fd-fa1b-e77cfc229879"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"cSV78ENQzZvq","executionInfo":{"status":"ok","timestamp":1638754812853,"user_tz":-540,"elapsed":12,"user":{"displayName":"Mads Jungersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15054749878452554668"}},"outputId":"57cc5eaa-7f0d-42dc-83bd-61e8706a454b"},"source":["\"\"\"\n","Change directory to where this file is located\n","\"\"\"\n","#%cd '/content/drive/MyDrive/DLSP/Drna-master'"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nChange directory to where this file is located\\n'"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"B8cDHgwXZ0eL"},"source":["# Loading data to colab (zip)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F-TKjua9Zzub","executionInfo":{"status":"ok","timestamp":1638754907165,"user_tz":-540,"elapsed":94322,"user":{"displayName":"Mads Jungersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15054749878452554668"}},"outputId":"f22badb6-fe53-4c48-cf9a-defdae29661b"},"source":["zip_path = \"/content/drive/MyDrive/DLSP/Drna-master/data/TestData.zip\"\n","!cp \"{zip_path}\" .\n","!unzip -q TestData.zip\n","!rm TestData.zip\n","\n","zip_path = \"/content/drive/MyDrive/DLSP/Drna-master/data/TrainData.zip\"\n","!cp \"{zip_path}\" .\n","!unzip -q TrainData.zip\n","!rm TrainData.zip"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["warning [TrainData.zip]:  76 extra bytes at beginning or within zipfile\n","  (attempting to process anyway)\n","error [TrainData.zip]:  reported length of central directory is\n","  -76 bytes too long (Atari STZip zipfile?  J.H.Holm ZIPSPLIT 1.1\n","  zipfile?).  Compensating...\n","error:  expected central file header signature not found (file #116969).\n","  (please check that you have transferred or created the zipfile in the\n","  appropriate BINARY mode and that you have compiled UnZip properly)\n"]}]},{"cell_type":"markdown","metadata":{"id":"J2aYcj2mvXrk"},"source":["# Dataloader Ny"]},{"cell_type":"code","metadata":{"id":"sWjqoL5uvc6J"},"source":["import torch.utils.data as data\n","import torchvision\n","from torchvision import transforms\n","from PIL import Image\n","from tqdm import tqdm\n","from time import sleep\n","\n","class TransformData(data.Dataset):\n","    def __init__(self, data, transform=None):\n","        self.data = data\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        x, y = self.data[index]\n","        if self.transform:\n","            x = self.transform(x)\n","        return x, y\n","    \n","    def __len__(self):\n","        return len(self.data)\n","\n","#testdata = torchvision.datasets.ImageFolder(\"TestData\", transform = test_transform)\n","#len(testdata)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rLG5Rx7tMPGT"},"source":["## Train RESNET50 fine-tuning all parameters (Small Images) LR as paper"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":659,"referenced_widgets":["ebd479848fe14a9e9af0cb8df43614d6","0b7f901113c143d18165eae5d46dcf05","e1ccd86ac86f430faad278005926f0b8","b61984e56eb54db8a2c46012a5b2ff20","90c7727d6ccf4fa18b3a0dd52f4ad1d1","5a3de439b99c42bfb9029a0d38e6d5a5","5801e1ac73994bf7a65a87ec775deefb","f74764d2da724f5eac1d320330510a59","0bf20de2450844f3bd44fadacf236383","01f48500412a40b28770e68943343604","4b9c990f1130401db179efb20c709ef5"]},"id":"sr_rMntWMY4Z","executionInfo":{"status":"error","timestamp":1638764720872,"user_tz":-540,"elapsed":9805077,"user":{"displayName":"Mads Jungersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15054749878452554668"}},"outputId":"05e6181e-9659-4473-ce08-810a0e9624b9"},"source":["import os\n","import torch.utils.data\n","import torch.nn.functional as F\n","import torchvision\n","from torchvision import transforms\n","from torch.nn import DataParallel\n","from datetime import datetime\n","from torch.optim.lr_scheduler import MultiStepLR\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/DLSP/Drna-master\")\n","from config import BATCH_SIZE, PROPOSAL_NUM, SAVE_FREQ, LR, WD, resume, save_dir, INPUT_SIZE, INPUT_SIZE_s, VAL_PROCENT, RESIZED_SIZE, RESIZED_SIZE_s\n","from torch import nn\n","#from core import resnet as model\n","#from core import model_vgg as model\n","#from core import data_loader\n","#from core.utils import init_log, progress_bar\n","from PIL import Image\n","import numpy as np\n","\n","BATCH_SIZE = 20\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","start_epoch = 1\n","save_dir = \"/content/drive/MyDrive/DLSP/models/\"\n","save_dir = os.path.join(save_dir, datetime.now().strftime('%Y%m%d_%H%M%S'))\n","if os.path.exists(save_dir):\n","    raise NameError('model dir exists!')\n","os.makedirs(save_dir)\n","print(save_dir)\n","#logging = init_log(save_dir)\n","#_print = logging.info\n","\n","################################################ DATA #############################\n","\n","train_transform = transforms.Compose([\n","    transforms.Resize(RESIZED_SIZE_s, Image.BILINEAR),\n","    transforms.RandomCrop(INPUT_SIZE_s),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n","                                 std=(0.229, 0.224, 0.225))\n","    ])\n","\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize(RESIZED_SIZE_s, Image.BILINEAR),\n","    transforms.CenterCrop(INPUT_SIZE_s),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n","                                 std=(0.229, 0.224, 0.225))\n","    ])\n","\n","\n","\n","\n","Full_train_dataset = torchvision.datasets.ImageFolder(\"TrainData\", transform = None)\n","train_nr = len(Full_train_dataset)\n","train_dataset, val_dataset = torch.utils.data.random_split(Full_train_dataset,\n","                                               [train_nr - int(np.ceil(train_nr*(VAL_PROCENT))), int(np.ceil(train_nr*(VAL_PROCENT)))],\n","                                               generator=torch.Generator().manual_seed(12))\n","\n","train_dataset =  TransformData(train_dataset, transform = train_transform)\n","val_dataset =  TransformData(val_dataset, transform = test_transform)\n","\n","\n","test_dataset = torchvision.datasets.ImageFolder(\"TestData\", transform = test_transform)\n","\n","\n","trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,\n","                                          shuffle=True, num_workers=2, drop_last=False)\n","\n","validationloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,\n","                                          shuffle=False, num_workers=2, drop_last=False)\n","\n","\n","testloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE,\n","                                         shuffle=False, num_workers=2, drop_last=False)\n","\n","print(\"Number of training data:\", len(train_dataset))\n","print(\"Number of validation data:\", len(val_dataset))\n","print(\"Number of test data:\", len(test_dataset))\n","\n","################################################ DATA #############################\n","\n","# define model\n","net = torchvision.models.resnet50(pretrained=True)\n","#net = model.resnet152(pretrained=True)\n","# CHANING THE LAST FC-LAYER TO FIT 10 CLASSES\n","num_ftrs = net.fc.in_features\n","net.fc = nn.Linear(num_ftrs, 10)\n","\n","resume = \"/content/drive/MyDrive/DLSP/models/TRAIN1/TRAIN1/017.ckpt\"\n","if resume:\n","    ckpt = torch.load(resume)\n","    net.load_state_dict(ckpt['net_state_dict'])\n","    start_epoch = ckpt['epoch'] + 1\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.SGD(net.parameters(), lr = 0.01)\n","net = net.cuda()\n","net = DataParallel(net)\n","\n","for epoch in range(start_epoch, 30):\n","    # begin training\n","    print('--' * 50)\n","    net.train()\n","    train_loss = 0\n","    train_correct = 0\n","    total = 0\n","    with tqdm(trainloader, unit=\"batch\") as tepoch:\n","        for data in tepoch:\n","            tepoch.set_description(f\"Epoch {epoch}\")\n","\n","            img, label = data[0].cuda(), data[1].cuda()\n","            batch_size = img.size(0)\n","            optimizer.zero_grad()\n","            outputs = net(img)\n","            loss = criterion(outputs,label)\n","            loss.backward()\n","            optimizer.step()\n","            # calculate accuracy\n","            _, predict = torch.max(outputs, 1)\n","            total += batch_size\n","            train_correct += torch.sum(predict.data == label.data)\n","            train_loss += loss.item() * batch_size\n","            tepoch.set_postfix(loss=train_loss/total, accuracy=100. * float(train_correct)/total)\n","            sleep(0.1)\n","    # Printing status after each epoch and perform validation    \n","    if epoch % SAVE_FREQ == 0:\n","        train_acc = float(train_correct) / total\n","        train_loss = train_loss / total\n","\n","        print(\n","            'epoch:{} - train loss: {:.3f} and train acc: {:.3f} total sample: {}'.format(\n","                epoch,\n","                train_loss,\n","                train_acc,\n","                total))\n","            \n","\t      # evaluate on test set\n","        test_loss = 0\n","        test_correct = 0\n","        total = 0\n","        net.eval()\n","        for i, data in enumerate(validationloader):\n","            img, label = data[0].cuda(), data[1].cuda()\n","            batch_size = img.size(0)\n","            \n","            outputs = net(img)\n","            loss = criterion(outputs,label)\n","            \n","            \n","            # calculate accuracy\n","            _, predict = torch.max(outputs, 1)\n","            total += batch_size\n","            test_correct += torch.sum(predict.data == label.data)\n","            test_loss += loss.item() * batch_size\n","\n","        test_acc = float(test_correct) / total\n","        test_loss = test_loss / total\n","        print(\n","            'epoch:{} - test loss: {:.3f} and test acc: {:.3f} total sample: {}'.format(\n","                epoch,\n","                test_loss,\n","                test_acc,\n","                total))\n","        \n","\n","\t      # save model\n","        net_state_dict = net.module.state_dict()\n","        if not os.path.exists(save_dir):\n","            os.mkdir(save_dir)\n","        torch.save({\n","            'epoch': epoch,\n","            'train_loss': train_loss,\n","            'train_acc': train_acc,\n","            'test_loss': test_loss,\n","            'test_acc': test_acc,\n","            'net_state_dict': net_state_dict},\n","            os.path.join(save_dir, '%03d.ckpt' % epoch))\n","\n","print('finishing training')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DLSP/models/20211206_014156\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"]},{"output_type":"stream","name":"stdout","text":["Number of training data: 93566\n","Number of validation data: 23392\n","Number of test data: 50182\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebd479848fe14a9e9af0cb8df43614d6","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/97.8M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18: 100%|██████████| 4679/4679 [44:56<00:00,  1.74batch/s, accuracy=77.9, loss=0.658]"]},{"output_type":"stream","name":"stdout","text":["epoch:18 - train loss: 0.658 and train acc: 0.779 total sample: 93566\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["epoch:18 - test loss: 1.653 and test acc: 0.573 total sample: 23392\n","----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19: 100%|██████████| 4679/4679 [45:20<00:00,  1.72batch/s, accuracy=79, loss=0.618]"]},{"output_type":"stream","name":"stdout","text":["epoch:19 - train loss: 0.618 and train acc: 0.790 total sample: 93566\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["epoch:19 - test loss: 1.713 and test acc: 0.582 total sample: 23392\n","----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 20: 100%|██████████| 4679/4679 [45:08<00:00,  1.73batch/s, accuracy=80.3, loss=0.586]"]},{"output_type":"stream","name":"stdout","text":["epoch:20 - train loss: 0.586 and train acc: 0.803 total sample: 93566\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["epoch:20 - test loss: 1.722 and test acc: 0.576 total sample: 23392\n","----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 21:  41%|████      | 1930/4679 [18:35<26:28,  1.73batch/s, accuracy=82.1, loss=0.526]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-ebdf620edb15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mtepoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_correct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0;31m# Printing status after each epoch and perform validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mSAVE_FREQ\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"o-cULy7p_Win"},"source":["## Test-acc and loss"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"id":"HS_PFPew_VmS","executionInfo":{"status":"error","timestamp":1638540258066,"user_tz":-540,"elapsed":9549768,"user":{"displayName":"Mads Code2 Jungersen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07751137562578499914"}},"outputId":"39e2f9ed-2141-42b3-ecbe-72c5629c6301"},"source":["import os\n","import torch.utils.data\n","import torch.nn.functional as F\n","import torchvision\n","from torchvision import transforms\n","from torch.nn import DataParallel\n","from datetime import datetime\n","from torch.optim.lr_scheduler import MultiStepLR\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/DLSP/Drna-master\")\n","from config import BATCH_SIZE, PROPOSAL_NUM, SAVE_FREQ, LR, WD, resume, save_dir, INPUT_SIZE, INPUT_SIZE_s, VAL_PROCENT, RESIZED_SIZE, RESIZED_SIZE_s\n","from torch import nn\n","#from core import resnet as model\n","#from core import model_vgg as model\n","#from core import data_loader\n","#from core.utils import init_log, progress_bar\n","from PIL import Image\n","import numpy as np\n","\n","BATCH_SIZE = 20\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","start_epoch = 1\n","save_dir = \"/content/drive/MyDrive/DLSP/models/\"\n","save_dir = os.path.join(save_dir, datetime.now().strftime('%Y%m%d_%H%M%S'))\n","if os.path.exists(save_dir):\n","    raise NameError('model dir exists!')\n","os.makedirs(save_dir)\n","print(save_dir)\n","#logging = init_log(save_dir)\n","#_print = logging.info\n","\n","################################################ DATA #############################\n","\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize(RESIZED_SIZE_s, Image.BILINEAR),\n","    transforms.CenterCrop(INPUT_SIZE_s),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n","                                 std=(0.229, 0.224, 0.225))\n","    ])\n","\n","\n","test_dataset = torchvision.datasets.ImageFolder(\"TestData\", transform = test_transform)\n","\n","\n","testloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE,\n","                                         shuffle=False, num_workers=2, drop_last=False)\n","\n","print(\"Number of test data:\", len(test_dataset))\n","\n","################################################ DATA #############################\n","\n","# define model\n","net = torchvision.models.resnet50(pretrained=True)\n","#net = model.resnet152(pretrained=True)\n","# CHANING THE LAST FC-LAYER TO FIT 10 CLASSES\n","num_ftrs = net.fc.in_features\n","net.fc = nn.Linear(num_ftrs, 10)\n","\n","resume = \"/content/drive/MyDrive/DLSP/models/BestModelSoFar/016.ckpt\"\n","if resume:\n","    if torch.cuda.is_available():\n","      ckpt = torch.load(resume)\n","    else:\n","      ckpt = torch.load(resume,map_location=torch.device('cpu'))\n","    net.load_state_dict(ckpt['net_state_dict'])\n","    start_epoch = ckpt['epoch'] + 1\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.SGD(net.parameters(), lr = 0.01)\n","if torch.cuda.is_available():\n","  net = net.cuda()\n","net = DataParallel(net)\n","\n","print('--' * 50)\n","net.eval()\n","\n","test_loss = 0\n","test_correct = 0\n","total = 0\n","with tqdm(testloader, unit=\"batch\") as tepoch:\n","    for data in tepoch:\n","        tepoch.set_description(f\"Testing..\")\n","        img, label = data[0], data[1]\n","        if torch.cuda.is_available():\n","            img, label = data[0].cuda(), data[1].cuda()\n","        batch_size = img.size(0)\n","        outputs = net(img)\n","        loss = criterion(outputs,label)\n","        # calculate accuracy\n","        _, predict = torch.max(outputs, 1)\n","        total += batch_size\n","        test_correct += torch.sum(predict.data == label.data)\n","        test_loss += loss.item() * batch_size\n","        tepoch.set_postfix(loss=test_loss/total, accuracy=100. * float(test_correct)/total)\n","        sleep(0.1)\n","\n","test_acc = float(test_correct) / total\n","test_loss = test_loss / total\n","\n","print('train loss: {:.3f} and train acc: {:.3f} total sample: {}'.format(\n","          test_loss,\n","          test_acc,\n","          total))\n","\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DLSP/models/20211203_112508\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"]},{"output_type":"stream","name":"stdout","text":["Number of test data: 50182\n","----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Testing..: 100%|██████████| 2510/2510 [2:39:07<00:00,  3.80s/batch, accuracy=57, loss=1.56]\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-758156ffefd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mtepoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_correct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_correct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_correct' is not defined"]}]}]}